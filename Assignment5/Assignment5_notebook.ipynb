{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29f95288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/commons/conda/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/06/17 16:34:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import mean\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class PSTool:\n",
    "    def pyspark_session(self, host_location):\n",
    "        \"\"\"\n",
    "        Creates and returns spark session object\n",
    "        \"\"\"\n",
    "        sc = SparkContext(host_location)  # Create spark context\n",
    "        spark = SparkSession(sc)  # Create session\n",
    "        return spark\n",
    "\n",
    "    def file_loader(self, path, delim, spark_obj):\n",
    "        data = spark_obj.read.options(delimiter=delim).csv(path)  # load file\n",
    "        data = data\n",
    "        return data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Instanciate object\n",
    "    pstool = PSTool()\n",
    "    # start session\n",
    "    spk = pstool.pyspark_session('local')\n",
    "    # load data\n",
    "    path = 'all_bacilli_subset.tsv'\n",
    "    df=pstool.file_loader(path, '\\t', spk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab0f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Protein _accession', 'Sequence_MD5_digest', 'Sequence_length', 'Analysis',\n",
    "# 'Signature_accession', 'Signature_description', 'Start location', 'Stop location',\n",
    "# 'Score', 'Status', 'Date', 'InterPro annotations', 'InterPro annotations' - description (e.g. BRCA2 repeat)\n",
    "#     (GO annotations (e.g. GO:0005515) - optional column; only displayed if –goterms option is switched on)\n",
    "#     (Pathways annotations (e.g. REACT_71) - optional column; only displayed if –pathways option is switched on)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec03a4",
   "metadata": {},
   "source": [
    "The TSV format presents the match data in columns as follows:\n",
    "\n",
    "    1. Protein accession (e.g. P51587)\n",
    "    2. Sequence MD5 digest (e.g. 14086411a2cdf1c4cba63020e1622579)\n",
    "    3. Sequence length (e.g. 3418)\n",
    "    4. Analysis (e.g. Pfam / PRINTS / Gene3D)\n",
    "    5. Signature accession (e.g. PF09103 / G3DSA:2.40.50.140)\n",
    "    6. Signature description (e.g. BRCA2 repeat profile)\n",
    "    7. Start location\n",
    "    8. Stop location\n",
    "    9. Score - is the e-value (or score) of the match reported by member database method (e.g. 3.1E-52)\n",
    "    10. Status - is the status of the match (T: true)\n",
    "    11. Date - is the date of the run\n",
    "    12. InterPro annotations - accession (e.g. IPR002093)\n",
    "    13. InterPro annotations - description (e.g. BRCA2 repeat)\n",
    "    14. (GO annotations (e.g. GO:0005515) - optional column; only displayed if –goterms option is switched on)\n",
    "    15. (Pathways annotations (e.g. REACT_71)-optional column; only displayed if –pathways option is switched on)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d87ad",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "How many distinct protein annotations are found in the dataset? I.e. how many distinc InterPRO numbers are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed9b7157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:================================================>      (177 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "InterPRO_distinc = df.select(\"_c11\").distinct().count()\n",
    "print(InterPRO_distinc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f5b00",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "How many annotations does a protein have on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba7e02b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_annot = df.select(\"_c11\").count()\n",
    "total_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0309f6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.278688524590164\n"
     ]
    }
   ],
   "source": [
    "avg_annot = total_annot/InterPRO_distinc\n",
    "print(avg_annot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d603d351",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "What is the most common GO Term found?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91676d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupBy(\"_c13\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29f440f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "go_list = []\n",
    "for i in df.filter(df._c13 != '-').select('_c13').collect():\n",
    "    go_list.extend(i[0].split(\"|\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f032889a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GO:0004743'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common = max(go_list, key = go_list.count)\n",
    "most_common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568fad13",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "What is the average size of an InterPRO feature found in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76858dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.select(\"_c2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bda9694e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340.235"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_size = df.select(mean('_c2')).collect()\n",
    "mean_size_float = float(str(mean_size[0]).replace('Row(avg(_c2)=', '').replace(')', ''))\n",
    "mean_size_float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c2e6fb",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "What is the top 10 most common InterPRO features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0042c37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('IPR001697', 10),\n",
       " ('IPR005814', 6),\n",
       " ('IPR000456', 5),\n",
       " ('IPR001867', 4),\n",
       " ('IPR004358', 4),\n",
       " ('IPR003776', 3),\n",
       " ('IPR001789', 3),\n",
       " ('IPR000551', 3),\n",
       " ('IPR000515', 3),\n",
       " ('IPR036890', 3)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interPRO_feat = []\n",
    "for i in df.filter(df._c11 != '-').select('_c11').collect():\n",
    "    interPRO_feat.extend(i)\n",
    "\n",
    "c = Counter(interPRO_feat)\n",
    "\n",
    "most_common_feats = c.most_common(10)\n",
    "most_common_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f572a90",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "If you select InterPRO features that are almost the same size (within 90-100%) as the protein itself, what is the top10 then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab8b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get protein lenght?????\n",
    "# Sequence length (e.g. 3418)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
