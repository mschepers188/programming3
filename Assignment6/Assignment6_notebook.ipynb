{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60410a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType,FloatType\n",
    "import pyspark.sql.functions as f\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d01b426",
   "metadata": {},
   "source": [
    "# Links\n",
    "\n",
    "* https://www.hackdeploy.com/pyspark-one-hot-encoding-with-countvectorizer/\n",
    "* https://techinplanet.com/split-lists-in-a-column-into-one-hot-encoded-features-in-pyspark/\n",
    "* https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.OneHotEncoder.html\n",
    "* https://towardsdatascience.com/countvectorizer-hashingtf-e66f169e2d4e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4a06db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating output folder\n",
      "Starting session\n",
      "Loading in file\n",
      "File loaded\n"
     ]
    }
   ],
   "source": [
    "class PSTool:\n",
    "    def __init__(self):\n",
    "        print('Creating output folder')\n",
    "        if os.path.exists('output'):\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs('output')\n",
    "\n",
    "    def pyspark_session(self, host_location):\n",
    "        \"\"\"\n",
    "        Creates and returns spark session object\n",
    "        \"\"\"\n",
    "        print('Starting session')\n",
    "        sc = SparkContext(host_location)  # Create spark context\n",
    "        spark = SparkSession(sc)  # Create session\n",
    "        return spark, sc\n",
    "\n",
    "    def file_loader(self, path, delim, spark_obj, schema):\n",
    "        print('Loading in file')\n",
    "        data = spark_obj.read.options(delimiter=delim).option(\"header\",\"False\").csv(path, schema=schema)\n",
    "        \n",
    "        print('File loaded')\n",
    "        return data\n",
    "\n",
    "    def get_questions(self, df):\n",
    "        pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pstool = PSTool()  # Instanciate object\n",
    "    spk, sc = pstool.pyspark_session('local[16]')  # start session\n",
    "    # load data\n",
    "#     path = '/data/dataprocessing/interproscan/all_bacilli.tsv'\n",
    "    path = 'all_bacilli_subset.tsv'\n",
    "    schema = StructType([\n",
    "        StructField(\"Protein_accession\", StringType(), True),\n",
    "        StructField(\"Sequence_MD5_digest\", StringType(), True),\n",
    "        StructField(\"Sequence_length\", IntegerType(), True),\n",
    "        StructField(\"Analysis\", StringType(), True),\n",
    "        StructField(\"Signature_accession\", StringType(), True),\n",
    "        StructField(\"Signature_description\", StringType(), True),\n",
    "        StructField(\"Start_location\", IntegerType(), True),\n",
    "        StructField(\"Stop_location\", IntegerType(), True),\n",
    "        StructField(\"Score\", FloatType(), True),\n",
    "        StructField(\"Status\", StringType(), True),\n",
    "        StructField(\"Date\", StringType(), True),\n",
    "        StructField(\"InterPro_annotations_accession\", StringType(), True),\n",
    "        StructField(\"InterPro_annotations_description\", StringType(), True),\n",
    "        StructField(\"GO_annotations\", StringType(), True),\n",
    "        StructField(\"Pathways_annotations\", StringType(), True)])\n",
    "    \n",
    "    df = pstool.file_loader(path, '\\t', spk, schema)\n",
    "#     pstool.get_questions(df)\n",
    "#     print('Closing spark session')\n",
    "#     spk.sparkContext.stop()\n",
    "#     df.printSchema()  # Shows column names and some info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d392b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 15\n",
      "count: 200\n"
     ]
    }
   ],
   "source": [
    "print('len:', len(df.columns))\n",
    "print('count:' , df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a51d1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Protein_accession',\n",
       " 'Sequence_MD5_digest',\n",
       " 'Sequence_length',\n",
       " 'Analysis',\n",
       " 'Signature_accession',\n",
       " 'Signature_description',\n",
       " 'Start_location',\n",
       " 'Stop_location',\n",
       " 'Score',\n",
       " 'Status',\n",
       " 'Date',\n",
       " 'InterPro_annotations_accession',\n",
       " 'InterPro_annotations_description',\n",
       " 'GO_annotations',\n",
       " 'Pathways_annotations']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc446aae",
   "metadata": {},
   "source": [
    "# Data munging\n",
    "\n",
    "First, the data has to be munged. \n",
    "* Remove entries without InterPRO number\n",
    "* Note which proteins features are >90% size of the protein and remove them. \"ProtID_select\"\n",
    "* Select the smaller features for the above found proteins. Proteins without large feature do not matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "375c16a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPRO_filt = df.filter(df[\"InterPro_annotations_accession\"] != '-').filter(df['Signature_description'] != '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dde0d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 15\n",
      "count: 97\n"
     ]
    }
   ],
   "source": [
    "print('len:', len(IPRO_filt.columns))\n",
    "print('count:' , IPRO_filt.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15359443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Protein_accession: string, Sequence_MD5_digest: string, Sequence_length: int, Analysis: string, Signature_accession: string, Signature_description: string, Start_location: int, Stop_location: int, Score: float, Status: string, Date: string, InterPro_annotations_accession: string, InterPro_annotations_description: string, GO_annotations: string, Pathways_annotations: string, perc: double]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sizes = IPRO_filt.withColumn('perc', abs(df.Start_location - df.Stop_location) / df.Sequence_length).sort('perc')\n",
    "df_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d3cf0",
   "metadata": {},
   "source": [
    "## Get descriptions into arrays\n",
    "\n",
    "This will be done to be able to one-hot encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78fadca2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         nameAsArray|\n",
      "+--------------------+\n",
      "|[Pyruvate, kinase...|\n",
      "|[Pyruvate, kinase...|\n",
      "|[Bacterial, senso...|\n",
      "|[Pyruvate, kinase...|\n",
      "|[Pyruvate, kinase...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_array = df_sizes.select(split(df_sizes.Signature_description,\" \").alias(\"nameAsArray\"))\n",
    "df_array.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1552a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "df_copy = df_array.select('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bd83a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_concat = df_copy.join(IPRO_filt.select('Sequence_length', 'Start_location', 'Stop_location', 'Score'))\n",
    "# df_concat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2032dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get term frequency vector through HashingTF\n",
    "from pyspark.ml.feature import HashingTF\n",
    "ht = HashingTF(inputCol=\"nameAsArray\", outputCol=\"features\")\n",
    "result = ht.transform(df_copy)\n",
    "# result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94c0d5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         nameAsArray|            features|\n",
      "+--------------------+--------------------+\n",
      "|[Pyruvate, kinase...|(262144,[25702,61...|\n",
      "|[Pyruvate, kinase...|(262144,[115560,2...|\n",
      "|[Bacterial, senso...|(262144,[41004,41...|\n",
      "|[Pyruvate, kinase...|(262144,[115560,2...|\n",
      "|[Pyruvate, kinase...|(262144,[115560,2...|\n",
      "|[Pyruvate, kinase...|(262144,[115560,2...|\n",
      "|[Bacterial, senso...|(262144,[41004,41...|\n",
      "|[Bacterial, senso...|(262144,[41004,41...|\n",
      "|[Pyruvate, kinase...|(262144,[115560,2...|\n",
      "|[Pyruvate, kinase...|(262144,[115560,2...|\n",
      "|[Bacterial, senso...|(262144,[41004,41...|\n",
      "|[Pyruvate, kinase...|(262144,[115560,2...|\n",
      "|[PpiC-type, pepti...|(262144,[7386,618...|\n",
      "|[Aminotransferase...|(262144,[19690,14...|\n",
      "|[Transaminase_4ab...|(262144,[99950],[...|\n",
      "|[PEP-utilising, e...|(262144,[72259,10...|\n",
      "|[Nudix, box, sign...|(262144,[22370,61...|\n",
      "|[PK, beta-barrel,...|(262144,[33826,16...|\n",
      "|       [GAF, domain]|(262144,[78676,10...|\n",
      "|[Ribosomal, prote...|(262144,[41365,61...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73939050",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(IPRO_filt.select(['Sequence_length', 'Start_location', 'Stop_location', 'Score']).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bebb5aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 1, 262144)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_3d = np.array(result.select('features').collect())\n",
    "x_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81a3e9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262144"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_3d[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c751af91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 262144)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped = x_3d.reshape(97, -1)\n",
    "reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4304b644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ca215a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = np.concatenate([test, reshaped], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06eee5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 262148)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faf05c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_array_from_df(data, column_list):\n",
    "#     return np.array(data.select(column_list).collect())\n",
    "    \n",
    "# labels = get_array_from_df(IPRO_filt, 'InterPro_annotations_accession')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b806e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"data_test.txt\", numeric_data, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4cc57c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048608\n",
      "1048592\n",
      "1048606\n",
      "1048611\n",
      "1048592\n",
      "1048590\n",
      "1048606\n",
      "1048611\n",
      "1048610\n",
      "1048610\n",
      "1048608\n",
      "1048608\n",
      "1048608\n",
      "1048604\n",
      "1048603\n",
      "1048607\n",
      "1048610\n",
      "1048610\n",
      "1048608\n",
      "1048609\n",
      "1048609\n",
      "1048591\n",
      "1048591\n",
      "1048591\n",
      "1048591\n",
      "1048610\n",
      "1048608\n",
      "1048609\n",
      "1048593\n",
      "1048591\n",
      "1048605\n",
      "1048610\n",
      "1048605\n",
      "1048590\n",
      "1048609\n",
      "1048590\n",
      "1048591\n",
      "1048590\n",
      "1048590\n",
      "1048590\n",
      "1048591\n",
      "1048608\n",
      "1048610\n",
      "1048609\n",
      "1048608\n",
      "1048606\n",
      "1048591\n",
      "1048606\n",
      "1048609\n",
      "1048609\n",
      "1048606\n",
      "1048590\n",
      "1048610\n",
      "1048593\n",
      "1048610\n",
      "1048605\n",
      "1048607\n",
      "1048590\n",
      "1048590\n",
      "1048592\n",
      "1048608\n",
      "1048610\n",
      "1048611\n",
      "1048607\n",
      "1048610\n",
      "1048610\n",
      "1048610\n",
      "1048610\n",
      "1048610\n",
      "1048611\n",
      "1048590\n",
      "1048590\n",
      "1048604\n",
      "1048608\n",
      "1048590\n",
      "1048590\n",
      "1048611\n",
      "1048590\n",
      "1048607\n",
      "1048610\n",
      "1048590\n",
      "1048590\n",
      "1048593\n",
      "1048590\n",
      "1048590\n",
      "1048592\n",
      "1048592\n",
      "1048592\n",
      "1048592\n",
      "1048592\n",
      "1048592\n",
      "1048611\n",
      "1048590\n",
      "1048610\n",
      "1048611\n",
      "1048610\n",
      "1048610\n"
     ]
    }
   ],
   "source": [
    "with open(\"data_test.txt\") as f:\n",
    "    for line in f:\n",
    "        print(len(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e49f7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
